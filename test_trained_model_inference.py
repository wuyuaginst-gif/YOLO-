#!/usr/bin/env python3
"""
ä½¿ç”¨è®­ç»ƒå¥½çš„ YOLO11 æ¨¡å‹è¿›è¡Œæ¨ç†æµ‹è¯•
"""

import sys
import time
from pathlib import Path
from PIL import Image
import numpy as np

sys.path.insert(0, str(Path(__file__).parent))

from ultralytics import YOLO


def find_trained_model():
    """æŸ¥æ‰¾æœ€æ–°è®­ç»ƒçš„æ¨¡å‹"""
    models_dir = Path("data/models")
    
    # æŸ¥æ‰¾æ‰€æœ‰è®­ç»ƒé¡¹ç›®
    trained_projects = sorted(
        models_dir.glob("yolo11_coco8_*/train/weights/best.pt"),
        key=lambda x: x.stat().st_mtime,
        reverse=True
    )
    
    if not trained_projects:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼è¯·å…ˆè¿è¡Œ test_yolo11_training.py")
        return None
    
    return str(trained_projects[0])


def test_inference_on_coco8():
    """ä½¿ç”¨ COCO8 éªŒè¯é›†å›¾ç‰‡è¿›è¡Œæ¨ç†æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("  YOLO11 è®­ç»ƒæ¨¡å‹æ¨ç†æµ‹è¯•")
    print("=" * 80 + "\n")
    
    # æŸ¥æ‰¾è®­ç»ƒå¥½çš„æ¨¡å‹
    model_path = find_trained_model()
    if not model_path:
        return
    
    print(f"âœ“ æ‰¾åˆ°è®­ç»ƒæ¨¡å‹: {model_path}")
    print(f"  æ¨¡å‹å¤§å°: {Path(model_path).stat().st_size / 1024 / 1024:.2f} MB\n")
    
    # åŠ è½½æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    start_time = time.time()
    model = YOLO(model_path)
    load_time = time.time() - start_time
    
    print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼(è€—æ—¶ {load_time:.2f}s)")
    print(f"  - ä»»åŠ¡ç±»å‹: {model.task}")
    print(f"  - ç±»åˆ«æ•°é‡: {len(model.names)}")
    print()
    
    # æŸ¥æ‰¾ COCO8 éªŒè¯é›†å›¾ç‰‡
    coco8_val_dir = Path("datasets/coco8/images/val")
    if not coco8_val_dir.exists():
        print("âŒ COCO8 éªŒè¯é›†ä¸å­˜åœ¨ï¼")
        return
    
    # è·å–æ‰€æœ‰éªŒè¯å›¾ç‰‡
    val_images = list(coco8_val_dir.glob("*.jpg"))
    print(f"æ‰¾åˆ° {len(val_images)} å¼ éªŒè¯å›¾ç‰‡\n")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("data/inference_results")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œæ¨ç†
    total_detections = 0
    total_inference_time = 0
    
    print("å¼€å§‹æ¨ç†...")
    print("-" * 80)
    
    for i, img_path in enumerate(val_images, 1):
        print(f"\n[{i}/{len(val_images)}] å›¾ç‰‡: {img_path.name}")
        
        # æ¨ç†
        start_time = time.time()
        results = model.predict(
            source=str(img_path),
            conf=0.25,
            iou=0.45,
            save=False,
            verbose=False
        )
        inference_time = time.time() - start_time
        total_inference_time += inference_time
        
        # è§£æç»“æœ
        result = results[0]
        boxes = result.boxes
        num_detections = len(boxes)
        total_detections += num_detections
        
        print(f"  â±ï¸  æ¨ç†æ—¶é—´: {inference_time*1000:.1f}ms")
        print(f"  ğŸ¯ æ£€æµ‹æ•°é‡: {num_detections}")
        
        if num_detections > 0:
            # æ˜¾ç¤ºæ¯ä¸ªæ£€æµ‹
            for j, box in enumerate(boxes):
                cls_id = int(box.cls[0])
                conf = float(box.conf[0])
                cls_name = model.names[cls_id]
                xyxy = box.xyxy[0].tolist()
                
                print(f"    [{j+1}] {cls_name} - ç½®ä¿¡åº¦: {conf:.3f} - BBox: {[int(x) for x in xyxy]}")
            
            # ä¿å­˜å¯è§†åŒ–ç»“æœ
            output_path = output_dir / f"result_{img_path.name}"
            result.save(filename=str(output_path))
            print(f"  ğŸ’¾ ä¿å­˜ç»“æœ: {output_path}")
        else:
            print(f"  â„¹ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("  æ¨ç†ç»Ÿè®¡")
    print("=" * 80)
    print(f"  æ€»å›¾ç‰‡æ•°: {len(val_images)}")
    print(f"  æ€»æ£€æµ‹æ•°: {total_detections}")
    print(f"  å¹³å‡æ¯å¼ å›¾ç‰‡æ£€æµ‹æ•°: {total_detections / len(val_images):.1f}")
    print(f"  å¹³å‡æ¨ç†æ—¶é—´: {total_inference_time / len(val_images) * 1000:.1f}ms")
    print(f"  æ€»æ¨ç†æ—¶é—´: {total_inference_time:.2f}s")
    print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}/")
    print("=" * 80 + "\n")


def test_inference_with_api():
    """æµ‹è¯•é€šè¿‡é¡¹ç›® API è¿›è¡Œæ¨ç†"""
    print("\n" + "=" * 80)
    print("  é€šè¿‡é¡¹ç›® API æµ‹è¯•æ¨ç†")
    print("=" * 80 + "\n")
    
    try:
        from backend.services.yolo_service import yolo_service
        from config.config import settings
        
        # æŸ¥æ‰¾è®­ç»ƒå¥½çš„æ¨¡å‹
        model_path = find_trained_model()
        if not model_path:
            return
        
        # å¤åˆ¶æ¨¡å‹åˆ° models ç›®å½•
        import shutil
        dest_path = settings.MODELS_DIR / "yolo11_coco8_trained.pt"
        shutil.copy(model_path, dest_path)
        print(f"âœ“ æ¨¡å‹å·²å¤åˆ¶åˆ°: {dest_path}\n")
        
        # ä½¿ç”¨é¡¹ç›®çš„ YOLO æœåŠ¡è¿›è¡Œæ¨ç†
        test_img = Path("datasets/coco8/images/val").glob("*.jpg")
        test_img = next(test_img, None)
        
        if not test_img:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
            return
        
        print(f"æµ‹è¯•å›¾ç‰‡: {test_img.name}")
        print("æ­£åœ¨æ¨ç†...\n")
        
        response = yolo_service.infer(
            image_path=str(test_img),
            model_name="yolo11_coco8_trained.pt",
            confidence=0.25,
            iou_threshold=0.45
        )
        
        if response.success:
            print("âœ“ API æ¨ç†æˆåŠŸï¼")
            print(f"  æ¨ç†æ—¶é—´: {response.inference_time*1000:.1f}ms")
            print(f"  æ£€æµ‹æ•°é‡: {len(response.detections)}")
            print(f"  å›¾åƒå°ºå¯¸: {response.image_shape}")
            
            for i, det in enumerate(response.detections, 1):
                print(f"  [{i}] {det.class_name} - ç½®ä¿¡åº¦: {det.confidence:.3f}")
        else:
            print(f"âŒ API æ¨ç†å¤±è´¥: {response.message}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    # 1. ä½¿ç”¨ COCO8 éªŒè¯é›†æµ‹è¯•
    test_inference_on_coco8()
    
    # 2. é€šè¿‡é¡¹ç›® API æµ‹è¯•
    test_inference_with_api()
    
    print("\nâœ… æ‰€æœ‰æ¨ç†æµ‹è¯•å®Œæˆï¼\n")


if __name__ == "__main__":
    main()
